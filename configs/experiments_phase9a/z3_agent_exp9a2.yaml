# Phase 9A: Reranker Experiment 2 - Chunk Size 700 (Iseng Test)
# Goal: Test reranker with larger chunks (700 vs 500)
#
# Baseline: Exp9a1 (chunk=500, reranker) â†’ Precision 0.828
# Expected: Unknown (exploratory test)
#
# Strategy:
# 1. Use chunk_size=700 (baseline's original chunk size)
# 2. Same reranker setup as Exp9a1
# 3. Compare: Does chunk size matter when using reranker?
#
# Hypothesis:
# - Larger chunks = more context = potentially better reranking?
# - OR larger chunks = more noise = worse precision?

domain_name: z3_agent_exp9a2

knowledge_base_dir: docs/
vector_store_dir: data/vector_stores/z3_agent_exp9a2/  # Need rebuild (700/50 combo)
golden_dataset: golden_datasets/z3_agent_tests.json

personality_config_path: content/reply_config1.json
supervisor_prompt_path: content/supervisor-prompt.txt

# Embedding: MPNet (proven winner from Phase 8)
embedding_model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2

llm_model: gemini-2.0-flash
llm_temperature: 0.7

# Base RAG parameters (CHANGED: chunk 700 instead of 500)
chunk_size: 700
chunk_overlap: 50
relevance_threshold: 0.3

# Reranker parameters
retrieval_k: 7              # Retrieve 7 candidates (more than Exp6's k=3)
use_reranker: true
reranker_model: BAAI/bge-reranker-base
reranker_top_k: 3           # Return top 3 after reranking
reranker_use_fp16: true     # Speed optimization (half precision)

# Notes:
# - retrieval_k=7: Give reranker enough candidates to choose from
# - reranker_top_k=3: Fair comparison with Exp6 (same final k)
# - Model: bge-reranker-base (~600MB, faster, good quality)
# - FP16: 2x faster with minimal accuracy loss (~1%)
